{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4T6G_EKhfnb"
   },
   "source": [
    "# YouTube Comment Scraper\n",
    "## Overview\n",
    "This Python script scrapes comments from videos, with keywords\n",
    "- body\n",
    "- weight\n",
    "- diet\n",
    "\n",
    "Three languages will be used for the study - Korean, English, and Bahasa Indonesia.\n",
    "\n",
    "This data collection is part of a study to understand the public's sentiments regarding body image and dieting, across different countries and cultures.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "YouTube Scraper boilerplate by [Akash Jain](https://francoisstamant.medium.com/) at [Medium](https://medium.com/analytics-vidhya/extracting-youtube-comments-using-selenium-b29ee4f743ef) and [François St-Amant](https://francoisstamant.medium.com/?source=post_page-----61ff197115d4--------------------------------) at [towardsdatascience](https://towardsdatascience.com/how-to-scrape-youtube-comments-with-python-61ff197115d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSWVYMzglnUm"
   },
   "source": [
    "### Step 1: Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PpU0cXtHmAOR"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from math import ceil\n",
    "\n",
    "# wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "# wd.get(\"https://www.webite-url.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3ctTT21O_TYy"
   },
   "outputs": [],
   "source": [
    "# Create a new .csv file to write data\n",
    "path = \"./data/youtube_comments_bodyimage.csv\"\n",
    "csv_file = open(path,'w', encoding=\"UTF-8\", newline=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G2zPsDJC_8Kt"
   },
   "outputs": [],
   "source": [
    "writer = csv.writer(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Q9Z6sZAs5SO",
    "outputId": "b4acae64-9e33-47d1-e9d9-8f63f9457c08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write header names\n",
    "writer.writerow(\n",
    "    ['url', 'link_title', 'channel', 'no_of_views', 'time_uploaded', 'comment', 'author', 'comment_posted', \n",
    "     'no_of_replies','upvotes','downvotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first scrape the youtube search page for \"body image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scraping https://www.youtube.com/results?search_query=body+image\n",
      "scraped  Girls Ages 6-18 Talk About Body Image | Allure\n",
      "scraped  The Science of Body Image\n",
      "scraped  Lili Reinhart’s Revealing Speech About Body Image | Glamour WOTY 2018\n",
      "scraped  TWRP - Body Image (Audio)\n",
      "scraped  Self Esteem Tips: Dealing with Body Image Issues\n",
      "scraped  9 Models on the Pressure to Lose Weight and Body Image | The Models | Vogue\n",
      "scraped  “Body Image” by Madilyn Paige | Saints Channel Studio\n",
      "scraped  What Happens When Strangers Get Real About Body Image\n",
      "scraped  Stop hating your body; start living your life | Taryn Brumfitt | TEDxAdelaide\n",
      "scraped  Jameela Jamil: Body image, the Kardashians and social media - BBC HARDtalk (2019)\n",
      "scraped  Positive Body Image & Self Esteem | Advice to Improve Self Worth | YOU ARE WORTHY | Kathryn Morgan\n",
      "scraped  Body Image + Journaling Tips | JENNGLEBELLS #3\n",
      "scraped  Wellcast - Self Esteem Tips: Dealing with Body Image Issues\n",
      "scraped  Media's Effects on Body Image\n",
      "scraped  Our Insecurities and Struggles with Body Image.\n",
      "scraped  Sam Smith x Jameela Jamil on body image and self acceptance | I Weigh Interviews\n",
      "scraped  Jennifer Lawrence talks body image - BBC Newsnight\n",
      "scraped  Self Esteem Tips: Dealing with Body Image Issues\n",
      "scraped  Our Body Image and Social Media: Live Life Unfiltered | Keisha & Teagan Simpson Simpson | TEDxOttawa\n",
      "scraped  Strangers Get Real About Their Body Image\n",
      "scraped  Kita vs Body image | Beropini eps. 49\n",
      "scraped  Body image: change the way you see yourself | Ira Querelle | TEDxMaastrichtSalon\n"
     ]
    }
   ],
   "source": [
    "link = \"https://www.youtube.com/results?search_query=covid\"\n",
    "\n",
    "# open chrome \n",
    "driver = webdriver.Chrome(executable_path='C:/WebDriver/bin/chromedriver.exe')\n",
    "driver.get(link)\n",
    "time.sleep(10)\n",
    "\n",
    "print(\"=\" * 40)  # Shows in terminal when youtube summary page with search keyword is being scraped\n",
    "print(\"Scraping \" + link)    \n",
    "time.sleep(20)    \n",
    "\n",
    "# scrap top 8 video URLS that pop up on search\n",
    "video_list = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "\n",
    "info = []\n",
    "urls = []\n",
    "titles = []\n",
    "channels = []\n",
    "no_of_views = []\n",
    "upload_dates = []\n",
    "\n",
    "# store URL and video title for videos\n",
    "for video in video_list:\n",
    "    urls.append(video.get_attribute('href'))\n",
    "    titles.append(video.get_attribute('title'))\n",
    "    print(\"scraped \", video.get_attribute('title'))\n",
    "\n",
    "# create data frame to store as csv\n",
    "df = pd.DataFrame(columns = ['url', 'title', 'channel', 'no_of_views', 'time_uploaded', 'comment', 'author', 'comment_posted', \n",
    "    'no_of_replies','upvotes','downvotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "1OQpHvc-VZmc",
    "outputId": "544de57f-450c-45f3-82ee-c6dac0dbb4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel name is  Allure\n",
      "no. of views is  5,014,874 views\n",
      "time uploaded is  Jun 1, 2018\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  AsapSCIENCE\n",
      "no. of views is  710,990 views\n",
      "time uploaded is  Dec 12, 2019\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  Glamour\n",
      "no. of views is  2,216,735 views\n",
      "time uploaded is  Nov 12, 2018\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  TWRPtube\n",
      "no. of views is  757,462 views\n",
      "time uploaded is  Jan 15, 2017\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  watchwellcast\n",
      "no. of views is  839,915 views\n",
      "time uploaded is  Apr 19, 2013\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  Vogue\n",
      "no. of views is  3,374,603 views\n",
      "time uploaded is  Apr 24, 2019\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  The Church of Jesus Christ of Latter-day Saints\n",
      "no. of views is  32,137 views\n",
      "time uploaded is  Nov 5, 2020\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  BBC Three\n",
      "no. of views is  736,116 views\n",
      "time uploaded is  Jan 22, 2018\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  TEDx Talks\n",
      "no. of views is  182,404 views\n",
      "time uploaded is  Feb 7, 2017\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  BBC HARDtalk\n",
      "no. of views is  96,709 views\n",
      "time uploaded is  Apr 22, 2020\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  Kathryn Morgan\n",
      "no. of views is  7,053 views\n",
      "time uploaded is  Jan 28, 2021\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  Jenn Im\n",
      "no. of views is  253,339 views\n",
      "time uploaded is  Dec 22, 2020\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  watchwellcast\n",
      "no. of views is  129,132 views\n",
      "time uploaded is  Apr 16, 2014\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  William Lewis\n",
      "no. of views is  66,240 views\n",
      "time uploaded is  Nov 14, 2013\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  Cimorelli\n",
      "no. of views is  112,902 views\n",
      "time uploaded is  Premiered Jan 17, 2021\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  Jameela Jamil\n",
      "no. of views is  84,821 views\n",
      "time uploaded is  Jun 13, 2020\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n",
      "SORT BY\n",
      "FINISHED SCROLLING!\n",
      "channel name is  BBC Newsnight\n",
      "no. of views is  501,902 views\n",
      "time uploaded is  Nov 12, 2013\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Scraping child links \n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-88c9f743f03a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#sort by top comments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"div#icon-label\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0msort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "# loop through each video\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    v_channel = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#upload-info yt-formatted-string\"))).text\n",
    "    print(\"channel name is \",v_channel)    \n",
    "    v_views = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#count span.view-count\"))).text\n",
    "    print(\"no. of views is \",v_views)\n",
    "    v_timeUploaded = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#date yt-formatted-string\"))).text\n",
    "    print(\"time uploaded is \",v_timeUploaded)\n",
    "\n",
    "    # retrieve comments\n",
    "    youtube_dict ={}\n",
    "\n",
    "\n",
    "    print(\"+\" * 40)  # Shows in terminal when details of a new video is being scraped\n",
    "    print(\"Scraping child links \")\n",
    "    #scroll down to load comments\n",
    "    driver.execute_script('window.scrollTo(0,390);')\n",
    "\n",
    "    # let comments load\n",
    "    time.sleep(15)\n",
    "\n",
    "    #sort by top comments\n",
    "    print(\"sorting by top comments\")\n",
    "    sort= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#icon-label\")))\n",
    "    sort.click()\n",
    "    \n",
    "    time.sleep(10)\n",
    "    topcomments =driver.find_element_by_xpath(\"\"\"//*[@id=\"menu\"]/a[1]/paper-item/paper-item-body/div[1]\"\"\")\n",
    "    topcomments.click()\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Loads 20 comments , scroll two times to load next set of 40 comments. \n",
    "    for i in range(0,2):\n",
    "        driver.execute_script(\"window.scrollTo(0,Math.max(document.documentElement.scrollHeight,document.body.scrollHeight,document.documentElement.clientHeight))\")\\\n",
    "        print(\"scrolling to load more comments\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    #count total number of comments and set index to number of comments if less than 50 otherwise set as 50. \n",
    "    totalcomments= len(driver.find_elements_by_xpath(\"\"\"//*[@id=\"content-text\"]\"\"\"))\n",
    "    \n",
    "\n",
    "    if totalcomments < 50:\n",
    "        index= totalcomments\n",
    "    else:\n",
    "        index= 50 \n",
    "    \n",
    "    # loop through each comment and scrape info\n",
    "    print(\"scraping through comments\")\n",
    "    ccount = 0\n",
    "    while ccount < index: \n",
    "        try:\n",
    "            comment = driver.find_elements_by_xpath('//*[@id=\"content-text\"]')[ccount].text\n",
    "        except:\n",
    "            comment = \"\"\n",
    "        try:\n",
    "            authors = driver.find_elements_by_xpath('//a[@id=\"author-text\"]/span')[ccount].text\n",
    "        except:\n",
    "            authors = \"\"\n",
    "        try:\n",
    "            comment_posted = driver.find_elements_by_xpath('//*[@id=\"published-time-text\"]/a')[ccount].text\n",
    "        except:\n",
    "            comment_posted = \"\"\n",
    "        try:\n",
    "            replies = driver.find_elements_by_xpath('//*[@id=\"more-text\"]')[ccount].text                    \n",
    "            if replies ==\"View reply\":\n",
    "                replies= 1\n",
    "            else:\n",
    "                replies =replies.replace(\"View \",\"\")\n",
    "                replies =replies.replace(\" replies\",\"\")\n",
    "        except:\n",
    "            replies = \"\"\n",
    "        try:\n",
    "            upvotes = driver.find_elements_by_xpath('//*[@id=\"vote-count-middle\"]')[ccount].text\n",
    "        except:\n",
    "            upvotes = \"\"\n",
    "\n",
    "        youtube_dict['url'] = url\n",
    "        youtube_dict['link_title'] = titles[counter]\n",
    "        youtube_dict['channel'] = v_channel\n",
    "        youtube_dict['no_of_views'] = v_views\n",
    "        youtube_dict['time_uploaded'] = v_timeUploaded\n",
    "        youtube_dict['comment'] = comment\n",
    "        youtube_dict['author'] = authors\n",
    "        youtube_dict['comment_posted'] = comment_posted\n",
    "        youtube_dict['no_of_replies'] = replies\n",
    "        youtube_dict['upvotes'] = upvotes\n",
    "        writer.writerow(youtube_dict.values())\n",
    "        \n",
    "        # increment comment counter\n",
    "        ccount = ccount + 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "scraping_youtube_commnets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
