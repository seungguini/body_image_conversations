{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comparative-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\seung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link_title</th>\n",
       "      <th>channel</th>\n",
       "      <th>no_of_views</th>\n",
       "      <th>time_uploaded</th>\n",
       "      <th>comment</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>comments_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>I swear, whoever is playing Plague Inc needs t...</td>\n",
       "      <td>486</td>\n",
       "      <td>['I', 'swear,', 'whoever', 'is', 'playing', 'P...</td>\n",
       "      <td>I swear, whoever is playing Plague Inc needs t...</td>\n",
       "      <td>['I', 'swear', ',', 'whoever', 'is', 'playing'...</td>\n",
       "      <td>['i', 'swear', ',', 'whoever', 'is', 'playing'...</td>\n",
       "      <td>['i', 'swear', 'whoever', 'is', 'playing', 'pl...</td>\n",
       "      <td>['swear', 'whoever', 'playing', 'plague', 'inc...</td>\n",
       "      <td>[('swear', 'JJ'), ('whoever', 'WP'), ('playing...</td>\n",
       "      <td>[('swear', 'a'), ('whoever', 'n'), ('playing',...</td>\n",
       "      <td>['swear', 'whoever', 'play', 'plague', 'inc', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>I am getting real tired of being part of  majo...</td>\n",
       "      <td>426</td>\n",
       "      <td>['I', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>I am getting real tired of being part of major...</td>\n",
       "      <td>['I', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>['i', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>['i', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>['getting', 'real', 'tired', 'part', 'major', ...</td>\n",
       "      <td>[('getting', 'VBG'), ('real', 'JJ'), ('tired',...</td>\n",
       "      <td>[('getting', 'v'), ('real', 'a'), ('tired', 'a...</td>\n",
       "      <td>['get', 'real', 'tired', 'part', 'major', 'his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>This channel's COVID reports are a model of ho...</td>\n",
       "      <td>797</td>\n",
       "      <td>['This', \"channel's\", 'COVID', 'reports', 'are...</td>\n",
       "      <td>This channel's COVID reports are a model of ho...</td>\n",
       "      <td>['This', 'channel', \"'s\", 'COVID', 'reports', ...</td>\n",
       "      <td>['this', 'channel', \"'s\", 'covid', 'reports', ...</td>\n",
       "      <td>['this', 'channel', \"'s\", 'covid', 'reports', ...</td>\n",
       "      <td>['channel', \"'s\", 'covid', 'reports', 'model',...</td>\n",
       "      <td>[('channel', 'NN'), (\"'s\", 'POS'), ('covid', '...</td>\n",
       "      <td>[('channel', 'n'), (\"'s\", 'n'), ('covid', 'n')...</td>\n",
       "      <td>['channel', \"'s\", 'covid', 'report', 'model', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>To people who understand science, the developm...</td>\n",
       "      <td>105</td>\n",
       "      <td>['To', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>To people who understand science, the developm...</td>\n",
       "      <td>['To', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>['to', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>['to', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>['people', 'understand', 'science', 'developme...</td>\n",
       "      <td>[('people', 'NNS'), ('understand', 'VBP'), ('s...</td>\n",
       "      <td>[('people', 'n'), ('understand', 'v'), ('scien...</td>\n",
       "      <td>['people', 'understand', 'science', 'developme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>So with these new variants this whole thing fe...</td>\n",
       "      <td>205</td>\n",
       "      <td>['So', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>So with these new variants this whole thing fe...</td>\n",
       "      <td>['So', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>['so', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>['so', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>['new', 'variants', 'whole', 'thing', 'feels',...</td>\n",
       "      <td>[('new', 'JJ'), ('variants', 'NNS'), ('whole',...</td>\n",
       "      <td>[('new', 'a'), ('variants', 'n'), ('whole', 'a...</td>\n",
       "      <td>['new', 'variant', 'whole', 'thing', 'feel', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         link_title  channel  \\\n",
       "0           0  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "1           1  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "2           2  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "3           3  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "4           4  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "\n",
       "    no_of_views time_uploaded  \\\n",
       "0  85,566 views  Jan 30, 2021   \n",
       "1  85,566 views  Jan 30, 2021   \n",
       "2  85,566 views  Jan 30, 2021   \n",
       "3  85,566 views  Jan 30, 2021   \n",
       "4  85,566 views  Jan 30, 2021   \n",
       "\n",
       "                                             comment upvotes  \\\n",
       "0  I swear, whoever is playing Plague Inc needs t...     486   \n",
       "1  I am getting real tired of being part of  majo...     426   \n",
       "2  This channel's COVID reports are a model of ho...     797   \n",
       "3  To people who understand science, the developm...     105   \n",
       "4  So with these new variants this whole thing fe...     205   \n",
       "\n",
       "                                         no_contract  \\\n",
       "0  ['I', 'swear,', 'whoever', 'is', 'playing', 'P...   \n",
       "1  ['I', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['This', \"channel's\", 'COVID', 'reports', 'are...   \n",
       "3  ['To', 'people', 'who', 'understand', 'science...   \n",
       "4  ['So', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                        comments_str  \\\n",
       "0  I swear, whoever is playing Plague Inc needs t...   \n",
       "1  I am getting real tired of being part of major...   \n",
       "2  This channel's COVID reports are a model of ho...   \n",
       "3  To people who understand science, the developm...   \n",
       "4  So with these new variants this whole thing fe...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  ['I', 'swear', ',', 'whoever', 'is', 'playing'...   \n",
       "1  ['I', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['This', 'channel', \"'s\", 'COVID', 'reports', ...   \n",
       "3  ['To', 'people', 'who', 'understand', 'science...   \n",
       "4  ['So', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                               lower  \\\n",
       "0  ['i', 'swear', ',', 'whoever', 'is', 'playing'...   \n",
       "1  ['i', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['this', 'channel', \"'s\", 'covid', 'reports', ...   \n",
       "3  ['to', 'people', 'who', 'understand', 'science...   \n",
       "4  ['so', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  ['i', 'swear', 'whoever', 'is', 'playing', 'pl...   \n",
       "1  ['i', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['this', 'channel', \"'s\", 'covid', 'reports', ...   \n",
       "3  ['to', 'people', 'who', 'understand', 'science...   \n",
       "4  ['so', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  ['swear', 'whoever', 'playing', 'plague', 'inc...   \n",
       "1  ['getting', 'real', 'tired', 'part', 'major', ...   \n",
       "2  ['channel', \"'s\", 'covid', 'reports', 'model',...   \n",
       "3  ['people', 'understand', 'science', 'developme...   \n",
       "4  ['new', 'variants', 'whole', 'thing', 'feels',...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [('swear', 'JJ'), ('whoever', 'WP'), ('playing...   \n",
       "1  [('getting', 'VBG'), ('real', 'JJ'), ('tired',...   \n",
       "2  [('channel', 'NN'), (\"'s\", 'POS'), ('covid', '...   \n",
       "3  [('people', 'NNS'), ('understand', 'VBP'), ('s...   \n",
       "4  [('new', 'JJ'), ('variants', 'NNS'), ('whole',...   \n",
       "\n",
       "                                         wordnet_pos  \\\n",
       "0  [('swear', 'a'), ('whoever', 'n'), ('playing',...   \n",
       "1  [('getting', 'v'), ('real', 'a'), ('tired', 'a...   \n",
       "2  [('channel', 'n'), (\"'s\", 'n'), ('covid', 'n')...   \n",
       "3  [('people', 'n'), ('understand', 'v'), ('scien...   \n",
       "4  [('new', 'a'), ('variants', 'n'), ('whole', 'a...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  ['swear', 'whoever', 'play', 'plague', 'inc', ...  \n",
       "1  ['get', 'real', 'tired', 'part', 'major', 'his...  \n",
       "2  ['channel', \"'s\", 'covid', 'report', 'model', ...  \n",
       "3  ['people', 'understand', 'science', 'developme...  \n",
       "4  ['new', 'variant', 'whole', 'thing', 'feel', '...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(['vader_lexicon'])\n",
    "\n",
    "with open('youtube_comments_clean.csv',encoding=\"utf8\") as file:\n",
    "    df = pd.read_csv(file)\n",
    "file.close()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "tutorial-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link_title</th>\n",
       "      <th>channel</th>\n",
       "      <th>no_of_views</th>\n",
       "      <th>time_uploaded</th>\n",
       "      <th>comment</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>comments_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>I swear, whoever is playing Plague Inc needs t...</td>\n",
       "      <td>486</td>\n",
       "      <td>['I', 'swear,', 'whoever', 'is', 'playing', 'P...</td>\n",
       "      <td>I swear, whoever is playing Plague Inc needs t...</td>\n",
       "      <td>['I', 'swear', ',', 'whoever', 'is', 'playing'...</td>\n",
       "      <td>['i', 'swear', ',', 'whoever', 'is', 'playing'...</td>\n",
       "      <td>['i', 'swear', 'whoever', 'is', 'playing', 'pl...</td>\n",
       "      <td>['swear', 'whoever', 'playing', 'plague', 'inc...</td>\n",
       "      <td>[('swear', 'JJ'), ('whoever', 'WP'), ('playing...</td>\n",
       "      <td>[('swear', 'a'), ('whoever', 'n'), ('playing',...</td>\n",
       "      <td>['swear', 'whoever', 'play', 'plague', 'inc', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>I am getting real tired of being part of  majo...</td>\n",
       "      <td>426</td>\n",
       "      <td>['I', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>I am getting real tired of being part of major...</td>\n",
       "      <td>['I', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>['i', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>['i', 'am', 'getting', 'real', 'tired', 'of', ...</td>\n",
       "      <td>['getting', 'real', 'tired', 'part', 'major', ...</td>\n",
       "      <td>[('getting', 'VBG'), ('real', 'JJ'), ('tired',...</td>\n",
       "      <td>[('getting', 'v'), ('real', 'a'), ('tired', 'a...</td>\n",
       "      <td>['get', 'real', 'tired', 'part', 'major', 'his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>This channel's COVID reports are a model of ho...</td>\n",
       "      <td>797</td>\n",
       "      <td>['This', \"channel's\", 'COVID', 'reports', 'are...</td>\n",
       "      <td>This channel's COVID reports are a model of ho...</td>\n",
       "      <td>['This', 'channel', \"'s\", 'COVID', 'reports', ...</td>\n",
       "      <td>['this', 'channel', \"'s\", 'covid', 'reports', ...</td>\n",
       "      <td>['this', 'channel', \"'s\", 'covid', 'reports', ...</td>\n",
       "      <td>['channel', \"'s\", 'covid', 'reports', 'model',...</td>\n",
       "      <td>[('channel', 'NN'), (\"'s\", 'POS'), ('covid', '...</td>\n",
       "      <td>[('channel', 'n'), (\"'s\", 'n'), ('covid', 'n')...</td>\n",
       "      <td>['channel', \"'s\", 'covid', 'report', 'model', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>To people who understand science, the developm...</td>\n",
       "      <td>105</td>\n",
       "      <td>['To', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>To people who understand science, the developm...</td>\n",
       "      <td>['To', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>['to', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>['to', 'people', 'who', 'understand', 'science...</td>\n",
       "      <td>['people', 'understand', 'science', 'developme...</td>\n",
       "      <td>[('people', 'NNS'), ('understand', 'VBP'), ('s...</td>\n",
       "      <td>[('people', 'n'), ('understand', 'v'), ('scien...</td>\n",
       "      <td>['people', 'understand', 'science', 'developme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We Know More About Those COVID-19 Variants. It...</td>\n",
       "      <td>SciShow</td>\n",
       "      <td>85,566 views</td>\n",
       "      <td>Jan 30, 2021</td>\n",
       "      <td>So with these new variants this whole thing fe...</td>\n",
       "      <td>205</td>\n",
       "      <td>['So', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>So with these new variants this whole thing fe...</td>\n",
       "      <td>['So', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>['so', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>['so', 'with', 'these', 'new', 'variants', 'th...</td>\n",
       "      <td>['new', 'variants', 'whole', 'thing', 'feels',...</td>\n",
       "      <td>[('new', 'JJ'), ('variants', 'NNS'), ('whole',...</td>\n",
       "      <td>[('new', 'a'), ('variants', 'n'), ('whole', 'a...</td>\n",
       "      <td>['new', 'variant', 'whole', 'thing', 'feel', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         link_title  channel  \\\n",
       "0           0  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "1           1  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "2           2  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "3           3  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "4           4  We Know More About Those COVID-19 Variants. It...  SciShow   \n",
       "\n",
       "    no_of_views time_uploaded  \\\n",
       "0  85,566 views  Jan 30, 2021   \n",
       "1  85,566 views  Jan 30, 2021   \n",
       "2  85,566 views  Jan 30, 2021   \n",
       "3  85,566 views  Jan 30, 2021   \n",
       "4  85,566 views  Jan 30, 2021   \n",
       "\n",
       "                                             comment upvotes  \\\n",
       "0  I swear, whoever is playing Plague Inc needs t...     486   \n",
       "1  I am getting real tired of being part of  majo...     426   \n",
       "2  This channel's COVID reports are a model of ho...     797   \n",
       "3  To people who understand science, the developm...     105   \n",
       "4  So with these new variants this whole thing fe...     205   \n",
       "\n",
       "                                         no_contract  \\\n",
       "0  ['I', 'swear,', 'whoever', 'is', 'playing', 'P...   \n",
       "1  ['I', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['This', \"channel's\", 'COVID', 'reports', 'are...   \n",
       "3  ['To', 'people', 'who', 'understand', 'science...   \n",
       "4  ['So', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                        comments_str  \\\n",
       "0  I swear, whoever is playing Plague Inc needs t...   \n",
       "1  I am getting real tired of being part of major...   \n",
       "2  This channel's COVID reports are a model of ho...   \n",
       "3  To people who understand science, the developm...   \n",
       "4  So with these new variants this whole thing fe...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  ['I', 'swear', ',', 'whoever', 'is', 'playing'...   \n",
       "1  ['I', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['This', 'channel', \"'s\", 'COVID', 'reports', ...   \n",
       "3  ['To', 'people', 'who', 'understand', 'science...   \n",
       "4  ['So', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                               lower  \\\n",
       "0  ['i', 'swear', ',', 'whoever', 'is', 'playing'...   \n",
       "1  ['i', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['this', 'channel', \"'s\", 'covid', 'reports', ...   \n",
       "3  ['to', 'people', 'who', 'understand', 'science...   \n",
       "4  ['so', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  ['i', 'swear', 'whoever', 'is', 'playing', 'pl...   \n",
       "1  ['i', 'am', 'getting', 'real', 'tired', 'of', ...   \n",
       "2  ['this', 'channel', \"'s\", 'covid', 'reports', ...   \n",
       "3  ['to', 'people', 'who', 'understand', 'science...   \n",
       "4  ['so', 'with', 'these', 'new', 'variants', 'th...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  ['swear', 'whoever', 'playing', 'plague', 'inc...   \n",
       "1  ['getting', 'real', 'tired', 'part', 'major', ...   \n",
       "2  ['channel', \"'s\", 'covid', 'reports', 'model',...   \n",
       "3  ['people', 'understand', 'science', 'developme...   \n",
       "4  ['new', 'variants', 'whole', 'thing', 'feels',...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [('swear', 'JJ'), ('whoever', 'WP'), ('playing...   \n",
       "1  [('getting', 'VBG'), ('real', 'JJ'), ('tired',...   \n",
       "2  [('channel', 'NN'), (\"'s\", 'POS'), ('covid', '...   \n",
       "3  [('people', 'NNS'), ('understand', 'VBP'), ('s...   \n",
       "4  [('new', 'JJ'), ('variants', 'NNS'), ('whole',...   \n",
       "\n",
       "                                         wordnet_pos  \\\n",
       "0  [('swear', 'a'), ('whoever', 'n'), ('playing',...   \n",
       "1  [('getting', 'v'), ('real', 'a'), ('tired', 'a...   \n",
       "2  [('channel', 'n'), (\"'s\", 'n'), ('covid', 'n')...   \n",
       "3  [('people', 'n'), ('understand', 'v'), ('scien...   \n",
       "4  [('new', 'a'), ('variants', 'n'), ('whole', 'a...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  ['swear', 'whoever', 'play', 'plague', 'inc', ...  \n",
       "1  ['get', 'real', 'tired', 'part', 'major', 'his...  \n",
       "2  ['channel', \"'s\", 'covid', 'report', 'model', ...  \n",
       "3  ['people', 'understand', 'science', 'developme...  \n",
       "4  ['new', 'variant', 'whole', 'thing', 'feel', '...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['no_contract', 'tokenized','lower','no_punct','pos_tags','wordnet_pos'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-rochester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-restaurant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
